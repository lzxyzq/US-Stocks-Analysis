{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Result/AAPL_TEST.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(test['Return'].dropna())\n",
    "bin_eval, bin_size = np.linspace(-0.1,0.1,10000,retstep=True)\n",
    "freq, bins = np.histogram(x1, bins=bin_eval, density=False)\n",
    "hist_den = np.array(freq)/len(x1)\n",
    "hist_cum = np.cumsum(hist_den)\n",
    "x_eval=np.linspace(-0.1+bin_size,0.1,9999, endpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL PDF ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a9078f884217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Scott's Rule\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Silverman's Rule\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Scott * 0.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mtdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def my_kde_bandwidth(obj, fac=1./5):\n",
    "    \"\"\"We use Scott's Rule, multiplied by a constant factor.\"\"\"\n",
    "    return np.power(obj.n, -1./(obj.d+4)) * fac\n",
    "\n",
    "kde = stats.gaussian_kde(x1)\n",
    "kde2 = stats.gaussian_kde(x1, bw_method='silverman')\n",
    "kde3 = stats.gaussian_kde(x1, bw_method=partial(my_kde_bandwidth, fac=0.2))\n",
    "kde4 = stats.gaussian_kde(x1, bw_method=partial(my_kde_bandwidth, fac=0.5))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_eval, kde(x_eval), 'k-', label=\"Scott's Rule\")\n",
    "ax.plot(x_eval, kde2(x_eval), 'b-', label=\"Silverman's Rule\")\n",
    "ax.plot(x_eval, kde3(x_eval), 'g-', label=\"Scott * 0.2\")\n",
    "ax.plot(x_eval, kde4(x_eval), 'c-', label=\"Scott * 0.5\")\n",
    "ax.bar(x_eval, freq, width=bin_size, fc='gray', edgecolor ='gray', label=\"Histogram\")\n",
    "\n",
    "ax.set_xlim([x_eval.min(), x_eval.max()])\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BANDWIDTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import scoreatpercentile\n",
    "from statsmodels.sandbox.nonparametric import kernels\n",
    "\n",
    "def _select_sigma(x, percentile=25):\n",
    "    \"\"\"\n",
    "    Returns the smaller of std(X, ddof=1) or normalized IQR(X) over axis 0.\n",
    "    References\n",
    "    ----------\n",
    "    Silverman (1986) p.47\n",
    "    \"\"\"\n",
    "    # normalize = norm.ppf(.75) - norm.ppf(.25)\n",
    "    normalize = 1.349\n",
    "    IQR = (scoreatpercentile(x, 75) - scoreatpercentile(x, 25)) / normalize\n",
    "    std_dev = np.std(x, axis=0, ddof=1)\n",
    "    if IQR > 0:\n",
    "        return np.minimum(std_dev, IQR)\n",
    "    else:\n",
    "        return std_dev\n",
    "\n",
    "def bw_silverman(x, kernel=None):\n",
    "    \"\"\"\n",
    "    Silverman's Rule of Thumb\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Array for which to get the bandwidth\n",
    "    kernel : CustomKernel object\n",
    "        Unused\n",
    "    Returns\n",
    "    -------\n",
    "    bw : float\n",
    "        The estimate of the bandwidth\n",
    "    Notes\n",
    "    -----\n",
    "    Returns .9 * A * n ** (-1/5.) where ::\n",
    "       A = min(std(x, ddof=1), IQR/1.349)\n",
    "       IQR = np.subtract.reduce(np.percentile(x, [75,25]))\n",
    "    References\n",
    "    ----------\n",
    "    Silverman, B.W. (1986) `Density Estimation.`\n",
    "    \"\"\"\n",
    "    A = _select_sigma(x)\n",
    "    n = len(x)\n",
    "    return .9 * A * n ** (-0.2)\n",
    "## Univariate Rule of Thumb Bandwidths ##\n",
    "def bw_scott(x, kernel=None):\n",
    "    \"\"\"\n",
    "    Scott's Rule of Thumb\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Array for which to get the bandwidth\n",
    "    kernel : CustomKernel object\n",
    "        Unused\n",
    "    Returns\n",
    "    -------\n",
    "    bw : float\n",
    "        The estimate of the bandwidth\n",
    "    Notes\n",
    "    -----\n",
    "    Returns 1.059 * A * n ** (-1/5.) where ::\n",
    "       A = min(std(x, ddof=1), IQR/1.349)\n",
    "       IQR = np.subtract.reduce(np.percentile(x, [75,25]))\n",
    "    References\n",
    "    ----------\n",
    "    Scott, D.W. (1992) Multivariate Density Estimation: Theory, Practice, and\n",
    "        Visualization.\n",
    "    \"\"\"\n",
    "    A = _select_sigma(x)\n",
    "    n = len(x)\n",
    "    return 1.059 * A * n ** (-0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL CDF ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yueqiang/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-09bf8614ffea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbandwidth_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_scott\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mkcu_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkcu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbandwidth_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Default bandwidth is the silverman of kernel gaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-09bf8614ffea>\u001b[0m in \u001b[0;36mkcu\u001b[0;34m(x1, x_eval, bandwidth)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbandwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbandwidth\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mcdf_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdf_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-09bf8614ffea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbandwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbandwidth\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mcdf_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdf_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "def kcu(x1,x_eval,bandwidth):\n",
    "    total_result = []\n",
    "    for i in x_eval:\n",
    "        if bandwidth != 0:\n",
    "            diff = [(i - x)/bandwidth for x in x1] \n",
    "            cdf_diff = norm.cdf(diff)\n",
    "            result = np.mean(cdf_diff)\n",
    "            total_result.append(result)\n",
    "    return total_result\n",
    "# Here to change the Bandwidth , \n",
    "bandwidth_1 = bw_silverman(x1,kernel='gaussian')\n",
    "bandwidth_2 = bw_scott(x1,kernel='gaussian')  \n",
    "bandwidth_3 = bw_scott(x1,kernel='gaussian') * 0.2\n",
    "bandwidth_4 = bw_scott(x1,kernel='gaussian') * 0.5\n",
    "\n",
    "kcu_result = np.array(kcu(x1,x_eval,bandwidth_1)) # Default bandwidth is the silverman of kernel gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_eval, kcu_result, 'b-', label=\"Estimated CDF\")\n",
    "ax.bar(x_eval, hist_cum, width=bin_size, fc='gray', edgecolor ='gray', label=\"Cumulative histogram\")\n",
    "ax.set_xlim([x_eval.min(), x_eval.max()])\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Pr(X<=x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>72.00</td>\n",
       "      <td>3343600</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>66.50</td>\n",
       "      <td>3408500</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.079464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>61.56</td>\n",
       "      <td>4119200</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.077190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1812900</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.025668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>65.00</td>\n",
       "      <td>2016900</td>\n",
       "      <td>A</td>\n",
       "      <td>0.080043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340182</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>163.45</td>\n",
       "      <td>1274675</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>-0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340183</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>161.52</td>\n",
       "      <td>1194883</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>-0.011878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340184</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>159.91</td>\n",
       "      <td>3591701</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>-0.010018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340185</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>163.17</td>\n",
       "      <td>3642531</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0.020181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340186</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>165.43</td>\n",
       "      <td>1620930</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0.013756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2340187 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   close   volume ticker    Return\n",
       "0       2000-01-03   72.00  3343600      A       NaN\n",
       "1       2000-01-04   66.50  3408500      A -0.079464\n",
       "2       2000-01-05   61.56  4119200      A -0.077190\n",
       "3       2000-01-06   60.00  1812900      A -0.025668\n",
       "4       2000-01-07   65.00  2016900      A  0.080043\n",
       "...            ...     ...      ...    ...       ...\n",
       "2340182 2020-10-05  163.45  1274675    ZTS -0.000612\n",
       "2340183 2020-10-06  161.52  1194883    ZTS -0.011878\n",
       "2340184 2020-10-07  159.91  3591701    ZTS -0.010018\n",
       "2340185 2020-10-08  163.17  3642531    ZTS  0.020181\n",
       "2340186 2020-10-09  165.43  1620930    ZTS  0.013756\n",
       "\n",
       "[2340187 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"Result/history_file_return.csv\")\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = np.array(test['Return'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap(ticker,shterm,dateN,window,target_ra,target_rb):\n",
    "    test_ticker = test[test['ticker'] == ticker]\n",
    "    target_ra=[target_ra]\n",
    "    target_rb=[target_rb]\n",
    "    date1 = pd.to_datetime(dateN) - timedelta(days=shterm)\n",
    "    x1_LT = test_ticker[(test_ticker['date'] <= dateN)]['Return'].dropna()\n",
    "    x1_ST = test_ticker[(test_ticker['date'] >= date1) & (test_ticker['date'] <= (pd.to_datetime(dateN) + timedelta(days=window)))]['Return'].dropna()\n",
    "    gap_LT = np.array(kcu(x1_LT,target_rb,bandwidth_1)) - np.array(kcu(x1_LT,target_ra,bandwidth_1))\n",
    "    gap_ST = np.array(kcu(x1_ST,target_rb,bandwidth_1)) - np.array(kcu(x1_ST,target_ra,bandwidth_1))\n",
    "    diff = gap_LT - gap_ST\n",
    "    volumn = test_ticker[test_ticker['date'] == (pd.to_datetime(dateN) + timedelta(days=window))]['volume'].values\n",
    "    price = test_ticker[test_ticker['date'] == (pd.to_datetime(dateN) + timedelta(days=window))]['close'].values\n",
    "    return diff,volumn,price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06147209])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "shterm = 365\n",
    "dateN = '2020-10-09'\n",
    "window = 0\n",
    "target_ra = 0.01\n",
    "target_rb = 0.05\n",
    "diff,volume,price = gap(ticker,shterm,dateN,window,target_ra,target_rb)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windows Cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "shterm = 365\n",
    "dateN_list = ['2015-01-02']\n",
    "ticker = \"MHK\"\n",
    "target_ra = 0.01\n",
    "target_rb = 0.05\n",
    "\n",
    "# Write the result with diff parameters into table\n",
    "total_diff = pd.DataFrame()\n",
    "total_volume = pd.DataFrame()\n",
    "total_price = pd.DataFrame()\n",
    "for i in range(len(dateN_list)):\n",
    "    dateN = dateN_list[i]\n",
    "    diff_result = []  \n",
    "    volume_result = []\n",
    "    price_result = []\n",
    "    # Every row need to be restart by none list to store the diff values with different windows\n",
    "    for window in range(31):\n",
    "        diff,volume,price = gap(ticker,shterm,dateN,window,target_ra,target_rb)\n",
    "        diff_result.append(diff)\n",
    "        volume_result.append(volume)\n",
    "        price_result.append(price)\n",
    "        \n",
    "    temp = pd.DataFrame(diff_result).T\n",
    "    temp[\"Ticker\"] = ticker \n",
    "    temp[\"dataN\"] = dateN\n",
    "    temp[\"Variable\"] = \"Gap\"\n",
    "    \n",
    "    temp1 = pd.DataFrame(price_result).T\n",
    "    temp1[\"Ticker\"] = ticker \n",
    "    temp1[\"dataN\"] = dateN\n",
    "    temp1[\"Variable\"] = \"Price\"\n",
    "    \n",
    "    temp2 = pd.DataFrame(volume_result).T\n",
    "    temp2[\"Ticker\"] = ticker \n",
    "    temp2[\"dataN\"] = dateN\n",
    "    temp2[\"Variable\"] = \"Volume\"\n",
    "    \n",
    "    total_diff = total_diff.append(temp)\n",
    "    total_price = total_price.append(temp1)\n",
    "    total_volume = total_volume.append(temp2)\n",
    "    \n",
    "for i in range(31):\n",
    "    total_diff = total_diff.rename(columns={i: \"W%d\"%(i)})\n",
    "    total_price = total_price.rename(columns={i: \"W%d\"%(i)})\n",
    "    total_volume = total_volume.rename(columns={i: \"W%d\"%(i)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([total_diff,total_volume,total_price])\n",
    "total = total[['Ticker', 'dataN', 'Variable','W0', 'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'W8', 'W9', 'W10',\n",
    "       'W11', 'W12', 'W13', 'W14', 'W15', 'W16', 'W17', 'W18', 'W19', 'W20',\n",
    "       'W21', 'W22', 'W23', 'W24', 'W25', 'W26', 'W27', 'W28', 'W29', 'W30']]\n",
    "# total.to_csv(\"total.csv\")\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH GAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal the Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticker_Names = pd.read_csv(\"Result/SP_500_Ticker_Name.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't run it. It will generate a new result and need a long time. \n",
    "import csv\n",
    "d1 = datetime(2015,1,1)   # from_date\n",
    "d2 = datetime(2020,7,15)\n",
    "delta = d2 - d1\n",
    "with open('Result/test.csv', 'w', encoding='utf-8') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter='&')\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['Ticker_Name','DateN','GAP'])\n",
    "    print('start...............')\n",
    "    for ticker_name in Ticker_Names['Ticker_Name']:\n",
    "        print(ticker_name)\n",
    "        try:\n",
    "            for i in range(delta.days+1):\n",
    "                dateN = d1 + timedelta(days=i)\n",
    "                result = gap(ticker_name,shterm=365,dateN=dateN,window=0,target_ra=0.01,target_rb=0.05)\n",
    "                csv_writer.writerow([ticker_name,dateN,result[0]])\n",
    "        except:\n",
    "            print(\"Error Ticker:\" + ticker_name)\n",
    "            continue\n",
    "    print('end...............')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "Ticker_Gap_Result = pd.read_csv('Result/test.csv')\n",
    "Ticker_Gap_Result['GAP_Value'] = 0\n",
    "for i in range(1027413):\n",
    "    try:\n",
    "        Ticker_Gap_Result.iloc[i,3] = ast.literal_eval(Ticker_Gap_Result.iloc[i,2])\n",
    "    except:\n",
    "        print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cal result \n",
    "Ticker_Gap_Result.to_csv('Result/Ticker_DateN_GapValue_Result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Gap Price and Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None Gap Ticker Name \n",
    "# Ticker_Gap_Result[Ticker_Gap_Result['GAP']=='[nan]']['Ticker_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Date colume it is datetime, the DateN is object can't merge with the date in the test\n",
    "file1 = pd.read_csv('Result/Ticker_DateN_GapValue_Result.csv')\n",
    "file1['Date'] = pd.to_datetime(file1['DateN'])\n",
    "file1 = file1[['Ticker_Name','GAP_Value','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = test[['ticker','close','volume','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = file1.merge(file2,how='left',left_on=['Ticker_Name','Date'],right_on=['ticker','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.rename(columns={'close': 'Price','volume':'Volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('Result/Ticker_DateN_GapValue_Price_Volume_Result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_gap(from_date,target_gap):\n",
    "    GapValue_Price_Volume = pd.read_csv('Result/Ticker_DateN_GapValue_Price_Volume_Result.csv')\n",
    "    return GapValue_Price_Volume[(GapValue_Price_Volume['GAP_Value'] >= 0.02) & (GapValue_Price_Volume['Date'] >= '2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal_result = search_gap('2015-01-01',0.02)\n",
    "cal_result[cal_result['Ticker_Name']=='A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal the filter result window value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_file = pd.read_csv('Result/Ticker_DateN_GapValue_Price_Volume_Result.csv')\n",
    "big_file[(big_file['Ticker_Name']=='ZION')& (big_file['Date']>='2015-01-06') & (big_file['Date']<='2015-02-06') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the date table  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get first record of every ticker from the filter result\n",
    "a = cal_result.groupby('Ticker_Name',as_index=False).first()\n",
    "# Ignore the ticker 'FRT','HBI','NLSN' that has some wrong in it \n",
    "a = a[~a['Ticker_Name'].isin(['FRT','HBI','NLSN'])][['Ticker_Name','GAP_Value','Date']]\n",
    "b = big_file.groupby('Ticker_Name',as_index=False)['Date'].max()\n",
    "c = cal_result.groupby('Ticker_Name',as_index=False)['Date'].max()\n",
    "date_table = a.merge(b,left_on='Ticker_Name',right_on='Ticker_Name')\n",
    "date_table = date_table.merge(c,left_on='Ticker_Name',right_on='Ticker_Name')\n",
    "date_table['Date_30_back'] = pd.to_datetime(date_table['Date_y']) - timedelta(days=30)\n",
    "\n",
    "def find_min(x,y):\n",
    "    if x < y :\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "date_table['Date_end'] = date_table.apply(lambda x: find_min(x.Date_30_back, pd.to_datetime(x.Date)), axis = 1)\n",
    "date_table = date_table.rename(columns={'Date_x':'Date_start'})\n",
    "date_table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Date_start and Date_end for every tickers (Except'FRT','HBI','NLSN' )in search file\n",
    "Date_start = first date of every ticker in the search file   \n",
    "Date_end = min(Date_30_back,Date)\n",
    "    Date is the max(date) in search file group by ticker\n",
    "    Date_y is the max(date) in big file group by ticker\n",
    "    Date_30_back is Date_y - 30 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dateN_list(start,end):\n",
    "    date_start = pd.to_datetime(start)\n",
    "    date_end = pd.to_datetime(end)\n",
    "    data_list = []\n",
    "    while date_start<=date_end:\n",
    "        data_list.append(date_start.strftime('%Y-%m-%d')) \n",
    "        date_start+=timedelta(days=1)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tickers = date_table['Ticker_Name'].tolist()\n",
    "ticker_date_period = {}\n",
    "for ticker in Tickers:\n",
    "    start = date_table[date_table['Ticker_Name'] == ticker]['Date_start'].tolist()[0]\n",
    "    end = date_table[date_table['Ticker_Name'] == ticker]['Date_end'].tolist()[0]\n",
    "    dateN_list_a = cal_dateN_list(start,end)\n",
    "    dateN_list_b = cal_result[cal_result['Ticker_Name']==ticker]['Date']\n",
    "    dateN_list = list(set(dateN_list_a).intersection(set(dateN_list_b)))\n",
    "    dateN_list = sorted(dateN_list)\n",
    "    ticker_date_period[ticker] = dateN_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count, Pool\n",
    "import numpy as np\n",
    "import time\n",
    "# cpu \n",
    "cores = cpu_count()\n",
    "partitions = cores\n",
    "\n",
    "print(\"cores' num: %d\" % partitions)\n",
    "\n",
    "def parallelize(data, func):\n",
    "\n",
    "    data_split = np.array_split(data, partitions) \n",
    "    pool = Pool(cores)\n",
    "    data = pool.map(func, data_split) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def get_wins_val(Tickers):\n",
    "    total_diff = pd.DataFrame()\n",
    "    total_volume = pd.DataFrame()\n",
    "    total_price = pd.DataFrame()\n",
    "#   Tickers = date_table['Ticker_Name'].tolist()\n",
    "    for ticker in Tickers:\n",
    "        print(ticker)\n",
    "        print(',')\n",
    "        dateN_list = ticker_date_period[ticker]\n",
    "        for i in range(len(dateN_list)):\n",
    "            dateN = dateN_list[i]\n",
    "            # default windows 0 to windows 30 \n",
    "            diff_result = 31*['None']  \n",
    "            volume_result = 31*['None'] \n",
    "            price_result = 31*['None'] \n",
    "\n",
    "            dateN_end_windows = pd.to_datetime(dateN)+timedelta(days=30)   \n",
    "\n",
    "            diff = big_file[(big_file['Ticker_Name'] == ticker) & (pd.to_datetime(big_file['Date']) >= dateN) \n",
    "                           & (pd.to_datetime(big_file['Date']) <= dateN_end_windows)]['GAP_Value'].tolist()\n",
    "            volume = big_file[(big_file['Ticker_Name'] == ticker) & (pd.to_datetime(big_file['Date']) >= dateN) \n",
    "                           & (pd.to_datetime(big_file['Date']) <= dateN_end_windows)]['Volume'].tolist()\n",
    "            price = big_file[(big_file['Ticker_Name'] == ticker) & (pd.to_datetime(big_file['Date']) >= dateN) \n",
    "                           & (pd.to_datetime(big_file['Date']) <= dateN_end_windows)]['Price'].tolist()\n",
    "            try:\n",
    "                for leng in range(len(diff)):\n",
    "                    diff_result[leng] = diff[leng]\n",
    "                    volume_result[leng] = volume[leng]\n",
    "                    price_result[leng] = price[leng]\n",
    "            except:\n",
    "                print(ticker)\n",
    "\n",
    "            temp = pd.DataFrame(diff_result).T\n",
    "            temp[\"Ticker\"] = ticker \n",
    "            temp[\"dataN\"] = dateN\n",
    "            temp[\"Variable\"] = \"Gap\"\n",
    "\n",
    "            temp1 = pd.DataFrame(price_result).T\n",
    "            temp1[\"Ticker\"] = ticker \n",
    "            temp1[\"dataN\"] = dateN\n",
    "            temp1[\"Variable\"] = \"Price\"\n",
    "\n",
    "            temp2 = pd.DataFrame(volume_result).T\n",
    "            temp2[\"Ticker\"] = ticker \n",
    "            temp2[\"dataN\"] = dateN\n",
    "            temp2[\"Variable\"] = \"Volume\"\n",
    "\n",
    "            total_diff = total_diff.append(temp)\n",
    "            total_price = total_price.append(temp1)\n",
    "            total_volume = total_volume.append(temp2)\n",
    "        for i in range(31):\n",
    "            total_diff = total_diff.rename(columns={i: \"W%d\"%(i)})\n",
    "            total_price = total_price.rename(columns={i: \"W%d\"%(i)})\n",
    "            total_volume = total_volume.rename(columns={i: \"W%d\"%(i)})\n",
    "\n",
    "        total = pd.concat([total_diff,total_volume,total_price])\n",
    "        total = total[['Ticker', 'dataN', 'Variable','W0', 'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'W8', 'W9', 'W10',\n",
    "                   'W11', 'W12', 'W13', 'W14', 'W15', 'W16', 'W17', 'W18', 'W19', 'W20',\n",
    "       'W21', 'W22', 'W23', 'W24', 'W25', 'W26', 'W27', 'W28', 'W29', 'W30']]\n",
    "        total.sort_values(by=['Ticker','dataN','Variable'])\n",
    "        total.to_csv('Result/Ticker_window/'+ticker+'_windows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = date_table['Ticker_Name'].tolist()\n",
    "time_start = time.time()\n",
    "results = parallelize(data_raw,get_wins_val)\n",
    "time_end = time.time()\n",
    "print('process time:',time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update_by_Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_by_day(Tickers,Year,Month,Day):\n",
    "    '''\n",
    "    Need to create the Result/Update/ file path in the laptop first.\n",
    "    '''\n",
    "    Date = str(Year)+'_'+str(Month)+\"_\"+str(Day)\n",
    "    Str_date = str(Year) + str(Month).zfill(2) + str(Day)\n",
    "    Result = pd.DataFrame()\n",
    "    Exception_list=[]\n",
    "    stack = []\n",
    "    validate = []\n",
    "    for i,Ticker in enumerate(Tickers):\n",
    "        try:\n",
    "            data = web.DataReader(Ticker, \"av-daily-adjusted\", start=datetime(Year, Month, Day),end=datetime(Year, Month, Day),api_key='OBN8PXVTLNCZ2ULQ')\n",
    "            data['Ticker'] = Ticker\n",
    "            data['date'] = pd.to_datetime(Str_date).strftime('%Y-%m-%d')\n",
    "            Result = Result.append(data)\n",
    "            print(Ticker)\n",
    "            time.sleep(10)\n",
    "        except:\n",
    "            if len(stack) > 0:\n",
    "                if i - stack.pop() == 1:\n",
    "                    validate.append(1)\n",
    "                    print(validate)\n",
    "                    if len(validate) == 4:\n",
    "                        break\n",
    "            stack.append(i)\n",
    "            print(\"An exception occurred: \" + Ticker)\n",
    "            Exception_list.append(Ticker)\n",
    "            time.sleep(60)\n",
    "    Result.to_csv('Result/Update/SP_500_'+ Date+'.csv',index=False,mode='a',header=False)\n",
    "    pd.DataFrame(Exception_list).to_csv('Result/Update/SP_500_' + Date + '_' + 'except_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 2020\n",
    "Month = 9\n",
    "Day = 17\n",
    "Date = str(Year)+'_'+str(Month)+\"_\"+str(Day)\n",
    "\n",
    "'''First time we should run all the tickers in the Excel file.'''\n",
    "df = pd.read_excel('./Data/US_SP_500.xlsx',skiprows=[0],)\n",
    "Tickers = df[\"Symbol\"][:3].tolist()\n",
    "\n",
    "'''After run the above two line codes , run the tickers in the except_list.csv several times \n",
    "until none tickers. If it doesn't work after a few tries, it's because of the resources.\n",
    "'''\n",
    "# df1 = pd.read_csv('Result/Update/SP_500_' + Date + '_' + 'except_list.csv')\n",
    "# Tickers = df1[\"0\"].tolist()\n",
    "\n",
    "update_by_day(Tickers,Year,Month,Day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_update_stock_by_day(file):\n",
    "    cal_data = pd.read_csv(file,header=None)\n",
    "    # Don't use the first row as column property\n",
    "    # Add the column name\n",
    "    cal_data.columns = ['open', 'high', 'low', 'close', 'adjusted close', 'volume',\n",
    "           'dividend amount', 'split coefficient', 'ticker', 'date']\n",
    "    cal_data = cal_data.drop(['open','high','low','adjusted close','dividend amount','split coefficient'], axis = 1)\n",
    "    cal_data = cal_data[['date','close','volume','ticker']]\n",
    "    return cal_data\n",
    "def merge_with_history(merge_file,history_file):\n",
    "#     history_data = pd.read_csv(\"Result/SP_500_history.csv\").drop(['open','high','low','adjusted close','dividend amount','split coefficient'], axis = 1)\n",
    "#     history_file = history_file[history_file['ticker'].isin(['AAPL','AMZN'])]\n",
    "    history_file = pd.concat([history_file,merge_file])\n",
    "    return history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"Result/Update/SP_500_2020_9_17.csv\"\n",
    "# merge_file = process_update_stock_by_day(file)\n",
    "# First time use the this file \"Result/SP_500_history.csv\"\n",
    "history_file = pd.read_csv(\"Result/SP_500_history.csv\").drop(['open','high','low','adjusted close','dividend amount','split coefficient'], axis = 1)\n",
    "# Scend time use the file \"Result/history_file.csv\"\n",
    "# history_file = pd.read_csv(\"Result/history_file.csv\")\n",
    "\n",
    "history_file = merge_with_history(merge_file,history_file)\n",
    "history_file = history_file.drop_duplicates()\n",
    "# history_file.to_csv('Result/history_file.csv',index=False)\n",
    "history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file['LOG_P'] = history_file[\"close\"].apply(np.log)\n",
    "history_file = history_file.sort_values(by=['ticker','date'])\n",
    "history_file['Return'] = history_file['LOG_P'] - history_file['LOG_P'].shift(1)\n",
    "history_file = history_file.drop(['LOG_P'],axis = 1)\n",
    "history_file.to_csv(\"Result/history_file_return.csv\",index=False)\n",
    "history_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update_by_Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_by_range(Tickers,start_date,end_date):\n",
    "    Exception_list=[]\n",
    "    for Ticker in Tickers:\n",
    "        Result = pd.DataFrame()\n",
    "        try:\n",
    "            data = web.DataReader(Ticker, \"av-daily-adjusted\", start=start_date,end=end_date,api_key='OBN8PXVTLNCZ2ULQ')\n",
    "            data['Ticker'] = Ticker\n",
    "            Result = Result.append(data)\n",
    "            Result.to_csv('Result/New_top500_tickers.csv',mode='a',header=False)\n",
    "            print(Ticker)\n",
    "            time.sleep(10)\n",
    "        except:\n",
    "            print(\"An exception occurred: \" + Ticker)\n",
    "            Exception_list.append(Ticker)\n",
    "            time.sleep(60)\n",
    "    pd.DataFrame(Exception_list).to_csv('Result/New_top500_tickers_except_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Update the tickers by date range\n",
    "# df = pd.read_excel('./Data/US_SP_500.xlsx',skiprows=[0],)\n",
    "# Tickers = df[\"Symbol\"].tolist()\n",
    "# 2.Update the failed tickers\n",
    "Tickers = pd.read_csv('Result/New_top500_tickers_except_list.csv',header=None)[1]\n",
    "start_date = datetime(2020, 7, 28)\n",
    "end_date = datetime(2020, 10, 10)\n",
    "update_by_range(Tickers,start_date,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_update_stock_by_date_range(file):\n",
    "    cal_data = pd.read_csv(file,header=None)\n",
    "    # Don't use the first row as column property\n",
    "    # Add the column name\n",
    "    cal_data.columns = ['date', 'open', 'high', 'low', 'close', 'adjusted close', 'volume',\n",
    "           'dividend amount', 'split coefficient', 'ticker']\n",
    "    cal_data = cal_data.drop(['open','high','low','adjusted close','dividend amount','split coefficient'], axis = 1)\n",
    "    cal_data = cal_data[['date','close','volume','ticker']]\n",
    "    return cal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Result/SP_500_history_1.csv'\n",
    "merge_file = process_update_stock_by_date_range(file)\n",
    "history_file = pd.read_csv(\"Result/SP_500_history.csv\").drop(['open','high','low','adjusted close','dividend amount','split coefficient'], axis = 1)\n",
    "history_file = merge_with_history(merge_file,history_file)\n",
    "history_file = history_file.drop_duplicates()\n",
    "# check the result , can delete this line code \n",
    "history_file[history_file['ticker'] == 'FB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result to the file.\n",
    "history_file.to_csv('Result/history_file.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file['LOG_P'] = history_file[\"close\"].apply(np.log)\n",
    "history_file = history_file.sort_values(by=['ticker','date'])\n",
    "history_file['Return'] = history_file['LOG_P'] - history_file['LOG_P'].shift(1)\n",
    "history_file = history_file.drop(['LOG_P'],axis = 1)\n",
    "history_file.to_csv(\"Result/history_file_return.csv\",index=False)\n",
    "history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('Result/history_file.csv')\n",
    "a[a['ticker'] == 'FB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add New Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Last</th>\n",
       "      <th>Change</th>\n",
       "      <th>%Chg</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>104.43</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-1.64%</td>\n",
       "      <td>105.39</td>\n",
       "      <td>105.82</td>\n",
       "      <td>104.17</td>\n",
       "      <td>175976.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corp</td>\n",
       "      <td>13.28</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.41%</td>\n",
       "      <td>13.26</td>\n",
       "      <td>13.37</td>\n",
       "      <td>13.09</td>\n",
       "      <td>1513599.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>American Airlines Gp</td>\n",
       "      <td>11.89</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-5.63%</td>\n",
       "      <td>12.39</td>\n",
       "      <td>12.46</td>\n",
       "      <td>11.85</td>\n",
       "      <td>41246260.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAN</td>\n",
       "      <td>Aaron's Holdings CO Inc</td>\n",
       "      <td>56.78</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-2.74%</td>\n",
       "      <td>57.28</td>\n",
       "      <td>57.94</td>\n",
       "      <td>56.11</td>\n",
       "      <td>102498.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>Applied Optoelect</td>\n",
       "      <td>10.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.10%</td>\n",
       "      <td>10.41</td>\n",
       "      <td>10.44</td>\n",
       "      <td>10.00</td>\n",
       "      <td>175374.0</td>\n",
       "      <td>11:47 ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                     Name    Last  Change    %Chg    Open    High  \\\n",
       "0      A     Agilent Technologies  104.43   -1.74  -1.64%  105.39  105.82   \n",
       "1     AA               Alcoa Corp   13.28   -0.19  -1.41%   13.26   13.37   \n",
       "2    AAL     American Airlines Gp   11.89   -0.71  -5.63%   12.39   12.46   \n",
       "3    AAN  Aaron's Holdings CO Inc   56.78   -1.60  -2.74%   57.28   57.94   \n",
       "4   AAOI        Applied Optoelect   10.16   -0.01  -0.10%   10.41   10.44   \n",
       "\n",
       "      Low      Volume      Time  \n",
       "0  104.17    175976.0  12:02 ET  \n",
       "1   13.09   1513599.0  12:02 ET  \n",
       "2   11.85  41246260.0  12:02 ET  \n",
       "3   56.11    102498.0  12:02 ET  \n",
       "4   10.00    175374.0  11:47 ET  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = pd.read_csv('Data/russell-3000-index-10-26-2020.csv')\n",
    "table1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol\n",
       "0   MSFT\n",
       "1   AAPL\n",
       "2   AMZN\n",
       "3     FB\n",
       "4  GOOGL"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP_500 = pd.read_excel('./Data/US_SP_500.xlsx',skiprows=[0],)[['Symbol']]\n",
    "SP_500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Last</th>\n",
       "      <th>Change</th>\n",
       "      <th>%Chg</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>DNKN</td>\n",
       "      <td>Dunkin' Brands Group</td>\n",
       "      <td>102.11</td>\n",
       "      <td>13.32</td>\n",
       "      <td>+15.00%</td>\n",
       "      <td>104.63</td>\n",
       "      <td>107.00</td>\n",
       "      <td>101.47</td>\n",
       "      <td>9899941.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AKBA</td>\n",
       "      <td>Akebia Therapeutics</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-10.69%</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5761184.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>FCEL</td>\n",
       "      <td>Fuelcell Energy Inc</td>\n",
       "      <td>2.29</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-3.78%</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.26</td>\n",
       "      <td>5702162.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>AMC</td>\n",
       "      <td>Amc Entertainment Holdings Inc</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-7.74%</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.72</td>\n",
       "      <td>5395490.0</td>\n",
       "      <td>12:02 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>DDD</td>\n",
       "      <td>3D Systems Corp</td>\n",
       "      <td>6.45</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-15.80%</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.44</td>\n",
       "      <td>4814672.0</td>\n",
       "      <td>12:01 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>EML</td>\n",
       "      <td>Eastern Company</td>\n",
       "      <td>22.00</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.59%</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>391.0</td>\n",
       "      <td>11:29 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>EBTC</td>\n",
       "      <td>Enterprise Bancorp</td>\n",
       "      <td>23.25</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-2.06%</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.25</td>\n",
       "      <td>353.0</td>\n",
       "      <td>09:53 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>BPRN</td>\n",
       "      <td>Bank of Princeton</td>\n",
       "      <td>20.12</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-1.66%</td>\n",
       "      <td>20.56</td>\n",
       "      <td>20.72</td>\n",
       "      <td>20.12</td>\n",
       "      <td>327.0</td>\n",
       "      <td>11:51 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>FGBI</td>\n",
       "      <td>First Gurty Banc</td>\n",
       "      <td>14.03</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.34%</td>\n",
       "      <td>14.19</td>\n",
       "      <td>14.19</td>\n",
       "      <td>14.03</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11:34 ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Downloaded from Barchart.com as of 10-26-2020 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Symbol  \\\n",
       "767                                                DNKN   \n",
       "95                                                 AKBA   \n",
       "949                                                FCEL   \n",
       "133                                                 AMC   \n",
       "730                                                 DDD   \n",
       "...                                                 ...   \n",
       "844                                                 EML   \n",
       "810                                                EBTC   \n",
       "390                                                BPRN   \n",
       "970                                                FGBI   \n",
       "1000  Downloaded from Barchart.com as of 10-26-2020 ...   \n",
       "\n",
       "                                Name    Last  Change     %Chg    Open    High  \\\n",
       "767             Dunkin' Brands Group  102.11   13.32  +15.00%  104.63  107.00   \n",
       "95               Akebia Therapeutics    2.84   -0.34  -10.69%    3.10    3.15   \n",
       "949              Fuelcell Energy Inc    2.29   -0.09   -3.78%    2.31    2.44   \n",
       "133   Amc Entertainment Holdings Inc    2.74   -0.23   -7.74%    2.92    2.97   \n",
       "730                  3D Systems Corp    6.45   -1.21  -15.80%    7.40    7.50   \n",
       "...                              ...     ...     ...      ...     ...     ...   \n",
       "844                  Eastern Company   22.00   -0.13   -0.59%   22.00   22.00   \n",
       "810               Enterprise Bancorp   23.25   -0.49   -2.06%   23.40   23.40   \n",
       "390                Bank of Princeton   20.12   -0.34   -1.66%   20.56   20.72   \n",
       "970                 First Gurty Banc   14.03   -0.19   -1.34%   14.19   14.19   \n",
       "1000                             NaN     NaN     NaN      NaN     NaN     NaN   \n",
       "\n",
       "         Low     Volume      Time  \n",
       "767   101.47  9899941.0  12:02 ET  \n",
       "95      2.81  5761184.0  12:02 ET  \n",
       "949     2.26  5702162.0  12:02 ET  \n",
       "133     2.72  5395490.0  12:02 ET  \n",
       "730     6.44  4814672.0  12:01 ET  \n",
       "...      ...        ...       ...  \n",
       "844    22.00      391.0  11:29 ET  \n",
       "810    23.25      353.0  09:53 ET  \n",
       "390    20.12      327.0  11:51 ET  \n",
       "970    14.03      313.0  11:34 ET  \n",
       "1000     NaN        NaN       NaN  \n",
       "\n",
       "[815 rows x 10 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = table1[~table1['Symbol'].isin(SP_500['Symbol'].to_list())]\n",
    "result_table = result_table.sort_values(by='Volume', ascending=False)\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list = result_table['Symbol'].to_list()\n",
    "len(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: BF.B\n",
      "CLH\n",
      "An exception occurred: CWE.A\n",
      "An exception occurred: BF.A\n"
     ]
    }
   ],
   "source": [
    "Tickers = ticker_list\n",
    "start_date = datetime(2000, 1, 1)\n",
    "end_date = datetime(2020, 10, 10)\n",
    "update_by_range(Tickers,start_date,end_date)\n",
    "# Failed ['BF.B','CWE.A','BF.A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>27.85</td>\n",
       "      <td>45399000</td>\n",
       "      <td>DNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>28.39</td>\n",
       "      <td>7421800</td>\n",
       "      <td>DNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>28.93</td>\n",
       "      <td>2200200</td>\n",
       "      <td>DNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>29.66</td>\n",
       "      <td>3147700</td>\n",
       "      <td>DNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>27.76</td>\n",
       "      <td>2483500</td>\n",
       "      <td>DNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680278</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>58.29</td>\n",
       "      <td>241156</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680279</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>57.79</td>\n",
       "      <td>257254</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680280</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>58.85</td>\n",
       "      <td>249438</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680281</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>59.07</td>\n",
       "      <td>141507</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680282</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>58.87</td>\n",
       "      <td>129756</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2680283 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  close    volume ticker\n",
       "0        2011-07-27  27.85  45399000   DNKN\n",
       "1        2011-07-28  28.39   7421800   DNKN\n",
       "2        2011-07-29  28.93   2200200   DNKN\n",
       "3        2011-08-01  29.66   3147700   DNKN\n",
       "4        2011-08-02  27.76   2483500   DNKN\n",
       "...             ...    ...       ...    ...\n",
       "2680278  2020-10-05  58.29    241156    CLH\n",
       "2680279  2020-10-06  57.79    257254    CLH\n",
       "2680280  2020-10-07  58.85    249438    CLH\n",
       "2680281  2020-10-08  59.07    141507    CLH\n",
       "2680282  2020-10-09  58.87    129756    CLH\n",
       "\n",
       "[2680283 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"Result/New_top500_tickers.csv\"\n",
    "merge_file = process_update_stock_by_date_range(file)\n",
    "merge_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>116.56</td>\n",
       "      <td>26614200</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>112.62</td>\n",
       "      <td>27059500</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>113.81</td>\n",
       "      <td>32029800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>110.00</td>\n",
       "      <td>27488300</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>111.44</td>\n",
       "      <td>31006800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340182</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>2390825</td>\n",
       "      <td>HFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340183</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>20.13</td>\n",
       "      <td>2303765</td>\n",
       "      <td>HFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340184</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>20.70</td>\n",
       "      <td>2342766</td>\n",
       "      <td>HFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340185</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>21.50</td>\n",
       "      <td>1827024</td>\n",
       "      <td>HFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340186</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>20.87</td>\n",
       "      <td>1901563</td>\n",
       "      <td>HFC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2340187 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date   close    volume ticker\n",
       "0        2000-01-03  116.56  26614200   MSFT\n",
       "1        2000-01-04  112.62  27059500   MSFT\n",
       "2        2000-01-05  113.81  32029800   MSFT\n",
       "3        2000-01-06  110.00  27488300   MSFT\n",
       "4        2000-01-07  111.44  31006800   MSFT\n",
       "...             ...     ...       ...    ...\n",
       "2340182  2020-10-05   20.03   2390825    HFC\n",
       "2340183  2020-10-06   20.13   2303765    HFC\n",
       "2340184  2020-10-07   20.70   2342766    HFC\n",
       "2340185  2020-10-08   21.50   1827024    HFC\n",
       "2340186  2020-10-09   20.87   1901563    HFC\n",
       "\n",
       "[2340187 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_file = pd.read_csv('Result/history_file.csv')\n",
    "history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>116.56</td>\n",
       "      <td>26614200</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>112.62</td>\n",
       "      <td>27059500</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>113.81</td>\n",
       "      <td>32029800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>110.00</td>\n",
       "      <td>27488300</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>111.44</td>\n",
       "      <td>31006800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680278</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>58.29</td>\n",
       "      <td>241156</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680279</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>57.79</td>\n",
       "      <td>257254</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680280</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>58.85</td>\n",
       "      <td>249438</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680281</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>59.07</td>\n",
       "      <td>141507</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680282</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>58.87</td>\n",
       "      <td>129756</td>\n",
       "      <td>CLH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5020470 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date   close    volume ticker\n",
       "0        2000-01-03  116.56  26614200   MSFT\n",
       "1        2000-01-04  112.62  27059500   MSFT\n",
       "2        2000-01-05  113.81  32029800   MSFT\n",
       "3        2000-01-06  110.00  27488300   MSFT\n",
       "4        2000-01-07  111.44  31006800   MSFT\n",
       "...             ...     ...       ...    ...\n",
       "2680278  2020-10-05   58.29    241156    CLH\n",
       "2680279  2020-10-06   57.79    257254    CLH\n",
       "2680280  2020-10-07   58.85    249438    CLH\n",
       "2680281  2020-10-08   59.07    141507    CLH\n",
       "2680282  2020-10-09   58.87    129756    CLH\n",
       "\n",
       "[5020470 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_file = merge_with_history(merge_file,history_file)\n",
    "history_file = history_file.drop_duplicates()\n",
    "history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()history_file[['ticker']].drop_duplicates()['ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file.to_csv('Result/history_file_1_1316tickers.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_by_day(Tickers,Year,Month,Day):\n",
    "    '''\n",
    "    Need to create the Result/Update/ file path in the laptop first.\n",
    "    '''\n",
    "    Date = str(Year)+'_'+str(Month)+\"_\"+str(Day)\n",
    "    Str_date = str(Year) + str(Month).zfill(2) + str(Day)\n",
    "    Result = pd.DataFrame()\n",
    "    Exception_list=[]\n",
    "    stack = []\n",
    "    validate = []\n",
    "    for i,Ticker in enumerate(Tickers):\n",
    "        try:\n",
    "            data = web.DataReader(Ticker, \"av-daily-adjusted\", start=datetime(Year, Month, Day),end=datetime(Year, Month, Day),api_key='OBN8PXVTLNCZ2ULQ')\n",
    "            data['Ticker'] = Ticker\n",
    "            data['date'] = pd.to_datetime(Str_date).strftime('%Y-%m-%d')\n",
    "            Result = Result.append(data)\n",
    "            print(Ticker)\n",
    "            time.sleep(10)\n",
    "        except:\n",
    "            if len(stack) > 0:\n",
    "                if i - stack.pop() == 1:\n",
    "                    validate.append(1)\n",
    "                    print(validate)\n",
    "                    if len(validate) == 4:\n",
    "                        break\n",
    "            stack.append(i)\n",
    "            print(\"An exception occurred: \" + Ticker)\n",
    "            Exception_list.append(Ticker)\n",
    "            time.sleep(60)\n",
    "    Result.to_csv('Result/Update/SP_500_'+ Date+'.csv',index=False,mode='a',header=False)\n",
    "    try:\n",
    "        web.DataReader(Ticker, \"av-daily-adjusted\", start=datetime(Year, Month, Day),end=datetime(Year, Month, Day),api_key='OBN8PXVTLNCZ2ULQ')\n",
    "    except:\n",
    "        Exception_list.extend(Tickers[i:])\n",
    "    pd.DataFrame(Exception_list).to_csv('Result/Update/SP_500_' + Date + '_' + 'except_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "aaa\n"
     ]
    }
   ],
   "source": [
    "Year = 2020\n",
    "Month = 9\n",
    "Day = 17\n",
    "Tickers = ['a','aaa','bbb','cccd','dddj','eeet','fff','hhha']\n",
    "update_by_day(Tickers,Year,Month,Day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_500 = pd.read_excel('./Data/US_SP_500.xlsx',skiprows=[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1bb3c515d875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSP_500\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "dict_ = Counter(SP_500['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc01a97f3870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_key\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTickers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_key\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_' is not defined"
     ]
    }
   ],
   "source": [
    "def get_key (dict, value):\n",
    "    return [k for k, v in dict.items() if v == value]\n",
    "Tickers = get_key (dict_, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the Source File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "result = pd.read_csv('Result/history_file_1_1316tickers.csv')\n",
    "result_tickers = result[['ticker']].drop_duplicates()['ticker'].tolist()\n",
    "result_tickers = result_tickers[3:]   \n",
    "# exclude the index 0 ,1 ,2 so 'MSFT','AAPL','AMZN' not in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_500 = pd.read_excel('./Data/US_SP_500.xlsx',skiprows=[0],)[['Symbol']]\n",
    "SP_500 = SP_500['Symbol'].tolist()[1:2] \n",
    "# Source tickers Only have ['AAPL', 'AMZN'] not in the result tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stickers = [i for i in SP_500 if i not in result_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'AMZN']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame(data= [['1','2','3']])\n",
    "result.to_csv('dataframe.csv',mode='a',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...............\n",
      "MSFT\n",
      "end...............\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "# Step 1: Check the file from the Result folder, if exists we read the last line record\n",
    "# Read the last line record and input the value into the parameter to make sure that \n",
    "# we can continue to run the function from the position that last time we stop.\n",
    "last_date_time = '2000-01-01'  # initial \n",
    "last_ticker_name = None # initial \n",
    "if os.path.exists('Result/test.csv'):\n",
    "    a = pd.read_csv('Result/test.csv')\n",
    "    last_date_time = a.tail(1).values[0][2]\n",
    "    last_ticker_name = a.tail(1).values[0][1]\n",
    "date_temp = last_date_time.split('-')\n",
    "last_date_time = datetime(int(date_temp[0]),int(date_temp[1]),int(date_temp[2])+1)\n",
    "# last_date_time + 1 means we continue to write the record from next day\n",
    "d1 = max(datetime(2015,1,1),last_date_time) # Start date\n",
    "d2 = datetime(2015,1,30)    # End Date\n",
    "delta = d2 - d1\n",
    "# ------------------------------------------------------------------\n",
    "# locate the ticker's position in the source ticker array\n",
    "index = 0\n",
    "if last_ticker_name:\n",
    "#   Ticker_Names = pd.read_csv(\"Result/SP_500_Ticker_Name.csv\") \n",
    "#   ticker_list = Ticker_Names['Ticker_Name']\n",
    "    ticker_list = ['AAPL','MSFT']\n",
    "    index = max(ticker_list.index(last_ticker_name),0)\n",
    "# column_name : ['Ticker_Name','DateN','GAP'])\n",
    "# The follow function we write the every row record to the csv by the append mode, hense \n",
    "# We continue to write records as long as the file exists, I set the header value false that means \n",
    "# the csv file only store the record values exclude the header(column name)\n",
    "# However we can set the header at the time when we read the csv :  \n",
    "# pd.read_csv('Result/test.csv',names=['Ticker_Name','DateN','GAP'])\n",
    "print('start...............')\n",
    "for ticker_name in ticker_list[index:]:\n",
    "    print(ticker_name)\n",
    "    try:\n",
    "        for i in range(delta.days+1):\n",
    "            dateN = d1 + timedelta(days=i)\n",
    "            result = gap(ticker_name,shterm=365,dateN=dateN,window=0,target_ra=0.01,target_rb=0.05)\n",
    "            temp = pd.DataFrame([[ticker_name,dateN,result[0]]])\n",
    "            temp.to_csv('Result/test.csv',mode='a',header=False)\n",
    "    except:\n",
    "        print(\"Error Ticker:\" + ticker_name)\n",
    "        continue\n",
    "print('end...............')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbaseconda58b5cd7f38ea4436811b709123b68308"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.804px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
